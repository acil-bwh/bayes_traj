
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://github.com/acil-bwh/bayes_traj/formulation/">
      
      
        <link rel="prev" href="..">
      
      
        <link rel="next" href="../inference/">
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.0, mkdocs-material-9.5.20">
    
    
      
        <title>Formulation - bayes_traj Documentation</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.66ac8b77.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#dirichlet-process-mixtures" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="bayes_traj Documentation" class="md-header__button md-logo" aria-label="bayes_traj Documentation" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            bayes_traj Documentation
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Formulation
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="bayes_traj Documentation" class="md-nav__button md-logo" aria-label="bayes_traj Documentation" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    bayes_traj Documentation
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Formulation
  </span>
  

      </a>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../inference/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Inference
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../bayes_traj_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tutorial
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<p>Here we describe our Bayesian formulation, beginning with a brief review of
Dirichlet process mixtures, a key element of our model.</p>
<h1 id="dirichlet-process-mixtures">Dirichlet Process Mixtures</h1>
<p><a href="https://www.jstor.org/stable/pdf/2958008.pdf?casa_token=tzi5CgijJnAAAAAA:P1JvaSlGmHtc9-8jJSib5nzt3lO_GgOBi5iiZth2bg-sbyMotPV7flSvBsIxiLTmYXdXAJSVA6qWIgLAbdvWtTOJiw9VNjGOUWy9vTzIhVgNRjCl6zA">Ferguson (1973)</a>
first introduced the Dirichlet process (DP) as a
measure on measures. It is parameterized by a base measure,
\(\mathit{G}_0\), and a positive scaling parameter \( \alpha \):
$$
  \mathit{G} \vert \{ \mathit{G}_0, \alpha \} \sim \text{DP}\left( \mathit{G}_0, \alpha \right)
$$
The notion of a Dirichlet process mixture (DPM) arises if we treat the
\( k^{th} \) draw from \( \mathit{G} \) as a parameter of the distribution over some
observation (<a href="https://www.jstor.org/stable/pdf/2958336.pdf?casa_token=JDOSeMgW_a4AAAAA:sYAU_MBeUgA113mrQnVM2SNbRjqMGvzBHMT8PUDGH-LQlliLQRlWbXKtD5Gl4ycRfCiTH4ABRPJnaY-UV-sA7HhwJzLT39QrVKWLRVPr2NeZRnLX-O4">Antoniak (1974)</a>).
DPMs can be interpreted as mixture models with an
infinite number of mixture components.</p>
<p>More recently,
<a href="https://www.cs.princeton.edu/courses/archive/fall07/cos597C/readings/BleiJordan2005.pdf">Blei and Jordan (2006)</a>
described a variational inference
algorithm for DPMs using the stick-breaking construction introduced in
<a href="https://groups.seas.harvard.edu/courses/cs281/papers/sethuraman-1994.pdf">Sethuraman (1991)</a>.
The stick-breaking construction represents \( G \) as
$$
  \pi_{k}( \mathbf{v} ) = \mathbf{v}_{k}\prod^{k-1}_{j=1}\left( 1-\mathbf{v}_{j}\right)
$$</p>
<p>$$
\mathit{G} = \sum_{i=1}^{\infty}\pi_{i}\left( \mathbf{v}\right)\delta_{\eta_{i}^{\ast}} 
$$
where \( \delta_{\eta_{i}^{\ast}}   \) is the Kronecker delta, and the
\( \mathbf{v}_{i} \) are distributed according to a beta distribution:
\( \mathbf{v}_{i} \sim \text{Beta}\left( 1, \alpha \right) \), and 
\( \eta_{i}^{\ast} \sim \mathit{G}_0 \). We use a DPM in our model to
automatically identify the number of trajectories that best explain our data.</p>
<h1 id="model-formulation">Model Formulation</h1>
<p>We consider a collection of multiple longitudinally observed target variables,
which can be continuous, binary, or a combination.
We let \(y_{g,i,d}\) represent the observation for individual \(g\)
\( (g=1,\dots,G) \) at the \( i^{th} \) occasion \( (i=1,\dots,n_g) \) for
target variable \(d\). 
Similarly, \(x_{g,i,m}\) represents predictor \(m\) \( (m=1,\dots,M)\) for
individual \(g\) on occasion \(i\).
Here, \(G\) is the total number of individuals in the data sample, \(n_g\)
is the number of observations per individual, and \(M\) is the number of
predictors. The likelihood in our formulation factorizes into two terms:
$$
p(\mathbf{Y}\mid \mathbf{Z}, \mathbf{W}, \boldsymbol{\lambda}, \mathbf{U}) =
p(\mathbf{Y}_c\mid \mathbf{Z}, \mathbf{W}_c, \boldsymbol{\lambda}, \mathbf{U})
p(\mathbf{Y}_b\mid \mathbf{Z}, \mathbf{W}_b)
$$
where we distinguish between the collection of \(D_c\) continuous target
variables, \(Y_c\), and the collection of \(D_b\) binary target variables,
\(Y_b\). The likelihood factors are given by:</p>
<p>$$
p(\mathbf{Y}_c\mid \mathbf{Z}, \mathbf{W}_c, \boldsymbol{\lambda}, \mathbf{U})=
\prod_{k=1}^{\infty} \prod_{g=1}^{G}\prod_{d_c=1}^{D_c}\left[
\prod_{i=1}^{n_g}\mathcal{N}\left(y_{g,i,d_c} \mid
(\mathbf{w}_{\cdot, d_c, k} + \mathbf{u}_{g, d_c, k})^{T} \mathbf{x}_{g,i,\cdot},
\lambda_{d_c,k}^{-1}\right)\right]^{z_{g, k}}
$$
and
$$
p(\mathbf{Y}_b\mid \mathbf{Z}, \mathbf{W}_b)=\prod_{k=1}^{\infty}\prod_{g=1}^{G} \prod_{d_b=1}^{D_b} 
\left[\prod_{i=1}^{n_g}
\frac{\exp(\mathbf{w}_{\cdot, d_b, k}^{T} \mathbf{x}_{g,i,\cdot})^{y_{g,i,d_b}}}
{1+\exp(\mathbf{w}_{\cdot, d_b, k}^{T} \mathbf{x}_{g,i,\cdot})}
\right]^{z_{g,k}}.
\label{YbLike}
$$</p>
<p>We formulate our model as a DPMM, which can be interpreted as a mixture model
with a potentially infinite number of mixture components
(<a href="https://www.jstor.org/stable/pdf/2958336.pdf?casa_token=JDOSeMgW_a4AAAAA:sYAU_MBeUgA113mrQnVM2SNbRjqMGvzBHMT8PUDGH-LQlliLQRlWbXKtD5Gl4ycRfCiTH4ABRPJnaY-UV-sA7HhwJzLT39QrVKWLRVPr2NeZRnLX-O4">Antoniak (1974)</a>).
The \(G \times \infty\) binary indicator matrix, \(\mathbf{Z}\), represents
the association between subjects and the potentially infinite number of latent
regression functions (trajectories), and \(k\) represents the group membership for each individual.
In the case of \(\mathbf{Y}_c\) this formulation can be see as mixture of linear
regressors, and in the case of \(\mathbf{Y}_b\) it can be seen as an infinite
mixture of logistic regressors.  </p>
<p>\( \mathbf{W}_c \) represents the \(M \times D_c \times \infty\) matrix of
predictor coefficients for the linear regressors, and  \( \mathbf{W}_b \)
represents the \(M \times D_b \times \infty\) matrix of predictor coefficients for
the logistic regressors. We put Gaussian priors over both \( \mathbf{W}_c\) and
\(\mathbf{W}_b\), where \( \boldsymbol{\mu}_0 \) and \( \boldsymbol{\lambda}_0 \)
capture practioner believe about coeffient values:</p>
<p>$$
p\left(\mathbf{W}_c \right)=
\prod_{m=1}^{M}
\prod_{d_c=1}^{D_c}
\prod_{k=1}^{\infty}
\mathcal{N}\left(w_{m, d_c, k} \mid
\mu_{0_{c_{m, d_c}}},
\lambda_{0_{c_{m, d_c}}}^{-1}\right)
$$</p>
<p>and
$$
p\left(\mathbf{W}_b \right)=
\prod_{m=1}^{M}
\prod_{d_b=1}^{D_b}
\prod_{k=1}^{\infty}
\mathcal{N}\left(w_{m, d_b, k}
\mid \mu_{0_{b_m, d_b}},
\lambda_{0_{b_m, d_b}}^{-1}\right)
\label{Wbprior}
$$</p>
<p>\( \mathbf{U} \) represents the \(G \times D_c \times \infty\) matrix of
(optional) random effects for the continuous target variables:</p>
<p>$$
p\left(\mathbf{U}\right)=
\prod_{g=1}^{G}
\prod_{d=1}^{D_c}
\prod_{k=1}^{\infty}
\mathcal{N}\left(\mathbf{u}_{g, d_c, k}
\mid \mathbf{0}, \mathbf{\Sigma_0} \right)
$$</p>
<p>(Note that the dimension length of random effect vectors is generally less than
\( \mathbf{M} \), the number of predictors. Elements of \( \mathbf{u}_{g, d_c, k} \)
corresponding to predictors with no random effects are set to 0.) Here we assume that
the random effects have mean \( \mathbf{0} \), and the unstructured covariance
matrix \( \boldsymbol{\Sigma}_0\) captures prior believe about predictor
variability within a trajectory subgroup.</p>
<p>We learn the residual precisions, \( \boldsymbol{\lambda} \), for each of the
\(D_c \times \infty\) linear regressors, and place gamma priors over these terms:
$$
p(\boldsymbol{\lambda})=
\prod_{k=1}^{\infty}
\prod_{d_c=1}^{D_c}
\mathrm{Gam}\left(\lambda_{d_c, k} \mid a_{0_{d_c}}, b_{0_{d_c}}\right).
$$</p>
<p>The nonparametric prior distribution over \( \mathbf{Z} \) is given by:
$$
p(\mathbf{Z} \mid \mathbf{v})=
\prod_{g=1}^{G} \prod_{k=1}^{\infty}\left(v_{k} \prod_{j=1}^{k-1}\left(1-v_{j}\right)\right)^{z_{g, k}}
$$
This can be considered a \( G\times \infty \) multinomial distribution with
parameters drawn for a DP using the stick-breaking construction
(see <a href="http://www.cs.princeton.edu/courses/archive/fall11/cos597C/reading/BleiJordan2005.pdf">Blei 2006</a>
and <a href="https://www.jstor.org/stable/pdf/24305538.pdf?casa_token=Os5nKQ7AeAMAAAAA:BbFJcPpxB-O10ntvO7ii9ruY3oeIAeTiAoQZ2X5rF9BhnaXIAV2rLqcx78Vji-vqRtOCJAeB1kWw_kcV1NvhmHssQamAxLb87mz0o_9oilKInFy_K80">Sethuraman 1994</a> for details),
where the elements
of \(\mathbf{v}\) are drawn from a beta distribution with concentration parameter \(\alpha\):
$$
p(\mathbf{v})=
\prod_{k=1}^{\infty}
\mathrm{Beta}\left(v_{k} \mid 1, \alpha\right).
\label{prior_v}
$$
The concentration parameter \(\alpha\) captures the practitionerâ€™s prior
belief about whether there are fewer groups (low scale parameter value) or
more groups (larger scale parameter value).
A benefit of the non-parametric framework is that the number of components
that best describe the observed data is automatically determined conditioned on
this value.</p>
<p>With these terms defined, the joint density is given as:
$$
p\left(\mathbf{Y}_c, 
\mathbf{Y}_b, 
\mathbf{W}_c, 
\mathbf{W}_b, 
\boldsymbol{\lambda}, 
\mathbf{Z}, 
\mathbf{v},
\mathbf{U}, 
\mid 
\mathbf{X},
\boldsymbol{\mu}_{c}, 
\boldsymbol{\lambda}_c, 
\boldsymbol{\mu}_b, 
\boldsymbol{\lambda}_b, 
\mathbf{a}_0, 
\mathbf{b}_0, 
\alpha,
\mathbf{\Sigma}_0, 
\right) = \\
p(\mathbf{Y}_c \mid \mathbf{Z}, \mathbf{W}_c, \boldsymbol{\lambda}, \mathbf{U})
p(\mathbf{Y}_b \mid \mathbf{Z}, \mathbf{W}_b)
p\left(\mathbf{W}_c \mid \boldsymbol{\mu}_c, \boldsymbol{\lambda}_c\right)
p\left(\mathbf{W}_b \mid \boldsymbol{\mu}_b, \boldsymbol{\lambda}_{b}\right) \\
p(\boldsymbol{\lambda} \mid \mathbf{a}_0, \mathbf{b}_0)
p(\mathbf{Z} \mid \mathbf{v}) 
p(\mathbf{v} \mid \alpha)
$$</p>







  
    
  
  


  <aside class="md-source-file">
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="Last update">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1-2.1-2M12.5 7v5.2l4 2.4-1 1L11 13V7h1.5M11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2v1.8Z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">September 9, 2024</span>
  </span>

    
    
    
    
  </aside>





                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": ["navigation.instant", "search.highlight"], "search": "../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.dd8806f2.min.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
    
  </body>
</html>